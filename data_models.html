<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Data &amp; Models | AI Credit Scoring Workshop</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <div class="container">
      <h1>AI Credit Scoring Workshop</h1>
      <nav>
        <a href="index.html">Home</a>
        <a href="overview.html">Overview</a>
        <a href="setup.html">Setup</a>
        <a href="data_models.html">Data &amp; Models</a>
        <a href="usage.html">Usage</a>
      </nav>
    </div>
  </header>
  <main class="container">
    <h2>Data &amp; Models</h2>
    <h3>Generating Synthetic Credit Data</h3>
    <p>
      The repository includes a Python script that generates a synthetic credit dataset with
      required event metadata. Using the <code>faker</code> library and random sampling, the script
      produces a CSV file with one million rows by default. Each row contains both customer features
      and AWS Fraud Detector metadata columns. The base features include name, age, occupation,
      annual income, monthly in‑hand salary, number of bank accounts, number of credit cards,
      interest rate, number of loans, type of loan(s), days delayed from the due date,
      number of delayed payments, credit mix, outstanding debt, credit utilization ratio,
      credit history age and total EMI per month.
    </p>

    <h4>Sample Code</h4>
    <p>Below is an excerpt from the dataset generation script showing the list of base columns and
    how each row is written to the CSV file:</p>
    <pre><code># Define the customer feature columns
base_columns = [
    "name", "age", "occupation", "annual_income", "monthly_inhand_salary",
    "num_bank_accounts", "num_credit_card", "interest_rate", "num_of_loan",
    "type_of_loan", "delay_from_due_date", "num_of_delayed_payment",
    "credit_mix", "outstanding_debt", "credit_utilization_ratio",
    "credit_history_age", "total_emi_per_month"
]

# Combine base and metadata columns and write header
header = base_columns + metadata_columns
writer.writerow(header)

# Write one row of synthetic data (simplified)
writer.writerow([
    faker.name(), random.randint(21, 60), faker.job(), random.randint(30000, 150000),
    random.randint(2000, 10000), random.randint(1, 7), random.randint(1, 6),
    random.randint(5, 20), random.randint(0, 3), "home", random.randint(0, 15),
    random.randint(0, 5), random.choice(credit_mix), random.randint(1000, 20000),
    round(random.uniform(20, 80), 1), f"{random.randint(1, 15)} Years and {random.randint(0, 11)} Months",
    random.randint(300, 900)
])
</code></pre>
    <p>
      Running this script will generate a large CSV file that you can use to test
      machine‑learning models or explore Fraud Detector’s capabilities.  Feel free to modify
      the number of rows or the distribution of values to suit your workshop objectives.
    </p>
    <h3>Rule‑Based Screening</h3>
    <p>
      Before calculating a score, the application evaluates each credit application against a set of
      screening rules. The backend loads rule definitions from a JSON configuration and iterates
      through the rules, checking each condition against the submitted form data. If a rule
      with an action of <code>reject</code> triggers, the API returns a response indicating
      rejection and includes the rule name and description. Otherwise, it records any flags and
      proceeds to compute a provisional score.
    </p>
    <h3>Score Estimation &amp; LLM Summarization</h3>
    <p>
      The FastAPI endpoint calculates a provisional credit score from repayment history, credit
      utilization, outstanding debt and the number of credit inquiries. It then constructs a prompt
      summarizing the applicant’s financial profile and uses AWS Bedrock to generate a succinct
      risk summary via a large language model. The summary is cleaned to remove any follow‑up
      questions before being returned to the user.
    </p>

    <h4>LLM Summarization Code</h4>
    <p>The backend uses AWS Bedrock via LangChain to create a concise, structured summary.
    The function constructs a system message instructing the model to act as a credit analyst
    and then sends the user’s profile as a human message:</p>
    <pre><code>def summarize_credit_profile(prompt: str) -&gt; str:
    messages = [
        SystemMessage(
            content=(
                "You are a credit analyst helping users understand their credit risk "
                "briefly and clearly. Provide a well-structured markdown report with "
                "headings for Summary, Key Strengths, Areas of Concern, and Recommendations. "
                "Use bullet points or numbered lists for readability and do not ask the "
                "user any questions."
            )
        ),
        HumanMessage(content=prompt),
    ]
    response = llm.invoke(messages)
    return response.content
</code></pre>
    <p>
      Participants can experiment with different prompts and see how the tone or depth of the
      summary changes.  Try adding more details to the prompt or adjusting the temperature
      parameter when creating the <code>ChatBedrock</code> instance to vary the creativity of the output.
    </p>
    <h3>Product Recommendations</h3>
    <p>
      A recommendation service employs a TF‑IDF vectorizer and cosine similarity to compare free‑text
      user queries with a set of pre‑defined credit card products. It returns the titles and
      descriptions of the top matching products to help applicants choose the most suitable
      financial products.
    </p>
    <h4>Recommendation Function</h4>
    <p>This helper uses a TF‑IDF vectorizer to find the most similar products to a free‑text query.</p>
    <pre><code>def recommend_products(query: str, top_k: int = 3) -&gt; List[Dict[str, str]]:
    if not query:
        return []
    q_vec = _VECTOR.transform([query])
    sims = cosine_similarity(q_vec, _MATRIX).ravel()
    if not np.any(sims):
        return []
    top_idxs = sims.argsort()[-top_k:][::-1]
    results: List[Dict[str, str]] = []
    for idx in top_idxs:
        prod = _PRODUCTS[idx]
        results.append({
            "title": prod.get("title", "Unknown Product"),
            "description": prod.get("text", ""),
        })
    return results
</code></pre>
    <p>
      You can extend this function by adding weighting to certain fields or exploring other
      similarity metrics such as word embeddings.  Building your own recommendation logic is a
      great way to experiment with feature engineering.
    </p>
  </main>
  <footer>
    <p>&copy; 2025 AI Credit Scoring Workshop. All rights reserved.</p>
  </footer>
</body>
</html>